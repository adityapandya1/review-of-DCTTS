{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ytig9a191QR9"
   },
   "source": [
    "<h4>Repository- <a>https://github.com/eazhary/dctts2</a></h4>\n",
    "\n",
    "<h4>Paper- <a>https://arxiv.org/abs/1710.08969</a></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKyvEwMC1QSC"
   },
   "source": [
    "<h1>Requirements</h1>\n",
    "<br>\n",
    "<span>\n",
    "<b>\n",
    "\n",
    "librosa==0.5.1<br>\n",
    "matplotlib==2.0.2<br>\n",
    "numpy==1.13.3<br>\n",
    "scipy==0.19.1<br>\n",
    "tensorflow==1.4.0<br>\n",
    "tqdm==4.19.2<br>\n",
    "</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>DOWNLOAD DATASET</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "aIcFqru31QSF",
    "outputId": "fa7c8ae5-2346-4b24-9098-a719cba4db09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "tar: Error opening archive: Failed to open 'LJSpeech-1.0.tar.bz2'\n"
     ]
    }
   ],
   "source": [
    "!wget http://data.keithito.com/data/speech/LJSpeech-1.0.tar.bz2\n",
    "!tar xjf LJSpeech-1.0.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>INSTALL ALL REQUIREMENTS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "K9k5ki8n1QSQ",
    "outputId": "1a8d8ea7-31b8-40fa-ddd1-7c9e102cdd42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
      "Collecting audioread>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/0b/940ea7861e0e9049f09dcfd72a90c9ae55f697c17c299a323f0148f913d2/audioread-2.1.8.tar.gz\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from librosa) (1.16.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from librosa) (1.2.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from librosa) (0.20.3)\n",
      "Collecting joblib>=0.12\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from librosa) (1.12.0)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/79/75/e22272b9c2185fc8f3af6ce37229708b45e8b855fd4bc38b4d6b040fff65/resampy-0.2.2.tar.gz (323kB)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from librosa) (0.43.1)\n",
      "Collecting soundfile>=0.9.0\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/de/24e4035f06540ebb4e9993238ede787063875b003e79c537511d32a74d29/SoundFile-0.10.3.post1-py2.py3.cp26.cp27.cp32.cp33.cp34.cp35.cp36.pp27.pp32.pp33-none-win_amd64.whl (689kB)\n",
      "Requirement already satisfied: llvmlite>=0.28.0dev0 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (0.28.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from soundfile>=0.9.0->librosa) (1.12.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n",
      "Building wheels for collected packages: librosa, audioread, resampy\n",
      "  Building wheel for librosa (setup.py): started\n",
      "  Building wheel for librosa (setup.py): finished with status 'done'\n",
      "  Created wheel for librosa: filename=librosa-0.7.2-cp37-none-any.whl size=1612889 sha256=b3a11a22cb1d9eabebadb6a0e8504b4d480b209e82e7612b29bb90fbbb803826\n",
      "  Stored in directory: C:\\Users\\Aditya Pandya\\AppData\\Local\\pip\\Cache\\wheels\\4c\\6e\\d7\\bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
      "  Building wheel for audioread (setup.py): started\n",
      "  Building wheel for audioread (setup.py): finished with status 'done'\n",
      "  Created wheel for audioread: filename=audioread-2.1.8-cp37-none-any.whl size=23097 sha256=3b16787ee23d657f2c13ac3372c24c54c81c0c5c08809a50064df8b2dfe4426a\n",
      "  Stored in directory: C:\\Users\\Aditya Pandya\\AppData\\Local\\pip\\Cache\\wheels\\b9\\64\\09\\0b6417df9d8ba8bc61a7d2553c5cebd714ec169644c88fc012\n",
      "  Building wheel for resampy (setup.py): started\n",
      "  Building wheel for resampy (setup.py): finished with status 'done'\n",
      "  Created wheel for resampy: filename=resampy-0.2.2-cp37-none-any.whl size=320724 sha256=d2ba183a49361d5acfbe2c729e06424f9008e44fb72063071710b0043a4376f0\n",
      "  Stored in directory: C:\\Users\\Aditya Pandya\\AppData\\Local\\pip\\Cache\\wheels\\fa\\c1\\56\\e0e12c6f7f3d2cdea9712b35136a2d40a7817c6210ec096485\n",
      "Successfully built librosa audioread resampy\n",
      "Installing collected packages: audioread, joblib, resampy, soundfile, librosa\n",
      "Successfully installed audioread-2.1.8 joblib-0.14.1 librosa-0.7.2 resampy-0.2.2 soundfile-0.10.3.post1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.10.0 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib) (1.16.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.16.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\aditya pandya\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (4.31.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3.1; however, version 20.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa --user\n",
    "!pip install matplotlib --user\n",
    "!pip install numpy --user\n",
    "!pip install scipy --user\n",
    "!pip install tqdm --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow\n",
    "!pip install tensorflow==1.14.0 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFvT01a_1QSX"
   },
   "source": [
    "<h1>HYPER PARAMETERS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIh3dlM91QSY"
   },
   "outputs": [],
   "source": [
    "data_dir = 'LJSpeech-1.0/' \n",
    "\n",
    "data = 'LJSpeech-1.0/'\n",
    "\n",
    "metafile = 'LJSpeech-1.0/metadata.csv'\n",
    "\n",
    "batch_size = 16 # alias = N\n",
    "\n",
    "warmup_steps = 4000\n",
    "\n",
    "logdir = 'logdir' # log directory\n",
    "\n",
    "logdirmag = 'logdirmag' # log directory\n",
    "\n",
    "logdirmel = 'logdirmel' # log directory\n",
    "\n",
    "sr = 22050 # Sampling Rate\n",
    "\n",
    "n_fft = 2048 # fft points (samples) (Fast Fourier Transform)\n",
    "\n",
    "fd = 1+n_fft//2\n",
    "\n",
    "frame_shift = 0.0125 # seconds\n",
    "\n",
    "frame_length = 0.05 # seconds\n",
    "\n",
    "hop_length = 256 # samples\tThis is dependent on the frame_shift.\n",
    "\n",
    "win_length = 1024 # samples This is dependent on the frame_length.\n",
    "\n",
    "n_mels = 80 # Number of Mel banks to generate\n",
    "\n",
    "sharpening_factor = 1.4 # Exponent for amplifying the predicted magnitude\n",
    "\n",
    "n_iter = 50 # Number of inversion iterations\n",
    "\n",
    "preemphasis = .97 # or None\n",
    "\n",
    "griffin_lim_iters=60\n",
    "\n",
    "power=1.5              # Power to raise magnitudes to prior to Griffin-Lim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_db = 100\n",
    "\n",
    "min_db = -100\n",
    "\n",
    "ref_db = 20\n",
    "\n",
    "max_grad_norm = 100.\n",
    "\n",
    "max_grad_val = 5.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model\n",
    "\n",
    "maxlen = 180 # Maximum number of letters in a sentance = T.\n",
    "\n",
    "Ty = 868 # Max number of timesteps \n",
    "\n",
    "Tyr = Ty//4 # Max number of timesteps \n",
    "\n",
    "e = 128\n",
    "\n",
    "d = 256\n",
    "\n",
    "c = 512\n",
    "\n",
    "lr = 2e-4\n",
    "\n",
    "init_lr=2e-4\n",
    "\n",
    "g=0.2\n",
    "\n",
    "b1 = 0.5\n",
    "\n",
    "b2 = 0.9\n",
    "\n",
    "eps = 1e-6\n",
    "\n",
    "logevery = 200\n",
    "\n",
    "dropout_rate = 0.1\n",
    "\n",
    "masking = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKMFhYIt1QSf"
   },
   "source": [
    "<h1>DATA PREPROCESSING</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UoG_P5kq1QSg",
    "outputId": "c34beb2a-d9c0-4f52-d539-813b1731d39a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'LJSpeech-1.0/mels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-60f73e7b59b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmel_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmag_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'LJSpeech-1.0/mels'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def get_spectrograms(sound_file):\n",
    "    '''Returns normalized log(melspectrogram) and log(magnitude) from `sound_file`.\n",
    "    Args:\n",
    "      sound_file: A string. The full path of a sound file.\n",
    "    Returns:\n",
    "      mel: A 2d array of shape (T, n_mels) <- Transposed\n",
    "      mag: A 2d array of shape (T, 1+n_fft/2) <- Transposed\n",
    "    '''\n",
    "    # Loading sound file\n",
    "    y, sr = librosa.load(sound_file, sr=22050)\n",
    "\n",
    "    # Trimming\n",
    "    y, _ = librosa.effects.trim(y)\n",
    "\n",
    "    # Preemphasis\n",
    "    y = np.append(y[0], y[1:] - preemphasis * y[:-1])\n",
    "\n",
    "    # stft\n",
    "    linear = librosa.stft(y=y,\n",
    "                          n_fft=n_fft,\n",
    "                          hop_length=hop_length,\n",
    "                          win_length=win_length)\n",
    "\n",
    "    # magnitude spectrogram\n",
    "    mag = np.abs(linear)  # (1+n_fft//2, T)\n",
    "\n",
    "    # mel spectrogram\n",
    "    mel_basis = librosa.filters.mel(sr, n_fft, n_mels)  # (n_mels, 1+n_fft//2)\n",
    "    mel = np.dot(mel_basis, mag)  # (n_mels, t)\n",
    "\n",
    "    # Sequence length\n",
    "    done = np.ones_like(mel[0, :]).astype(np.int32)\n",
    "\n",
    "    # to decibel\n",
    "    mel = librosa.amplitude_to_db(mel)\n",
    "    mag = librosa.amplitude_to_db(mag)\n",
    "\n",
    "    # normalize\n",
    "    mel = np.clip((mel - ref_db + max_db) / max_db, 0, 1)\n",
    "    mag = np.clip((mag - ref_db + max_db) / max_db, 0, 1)\n",
    "\n",
    "    # Transpose\n",
    "    mel = mel.T.astype(np.float32)  # (T, n_mels)\n",
    "    mag = mag.T.astype(np.float32)  # (T, 1+n_fft//2)\n",
    "\n",
    "    return mel, done, mag\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wav_folder = os.path.join(data, 'wavs')\n",
    "    # wav_folder = os.path.join('/data/private/voice/nick', 'Tom')\n",
    "    mel_folder = os.path.join(data, 'mels')\n",
    "    dones_folder = os.path.join(data, 'dones')\n",
    "    mag_folder = os.path.join(data, 'mags')\n",
    "\n",
    "    for folder in (mel_folder, dones_folder, mag_folder):\n",
    "        if not os.path.exists(folder): os.mkdir(folder)\n",
    "\n",
    "    files = glob.glob(os.path.join(wav_folder, \"*\"))\n",
    "    for f in tqdm.tqdm(files):\n",
    "        fname = os.path.basename(f)\n",
    "        mel, dones, mag = get_spectrograms(f)  # (n_mels, T), (1+n_fft/2, T) float32\n",
    "        np.save(os.path.join(mel_folder, fname.replace(\".wav\", \".npy\")), mel)\n",
    "        np.save(os.path.join(dones_folder, fname.replace(\".wav\", \".npy\")), dones)\n",
    "        np.save(os.path.join(mag_folder, fname.replace(\".wav\", \".npy\")), mag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FnL_F3QT1QSn"
   },
   "source": [
    "<h1>AUDIO</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbGki_qi1QSo"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.filters\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "#import tensorflow as tf\n",
    "\n",
    "\n",
    "def load_wav(path):\n",
    "    \n",
    "    '''\n",
    "        Load an audio file as a floating point time series.\n",
    "\n",
    "        Audio will be automatically resampled to the given rate (default sr=22050).\n",
    "\n",
    "        To preserve the native sampling rate of the file, use sr=None.\n",
    "\n",
    "        ARGS: File Path\n",
    "\n",
    "        RETURNS: Time-Intensity Representaion Of WaveForm\n",
    "        \n",
    "        '''\n",
    "    \n",
    "    return librosa.core.load(path, sr=sr)[0]\n",
    "\n",
    "\n",
    "def save_wav(wav, path):\n",
    "    \n",
    "    '''\n",
    "        Saves Audio File To The Given Path\n",
    "    \n",
    "        ARGS: Time-Intensity Representaion Of Waveform , Path\n",
    "        \n",
    "        RETURNS: Nothing,Saves the Waveform To The Path\n",
    "    '''\n",
    "    \n",
    "    wav *= 32767 / max(0.01, np.max(np.abs(wav)))\n",
    "    librosa.output.write_wav(path, wav.astype(np.int16), sr)\n",
    "    \n",
    "\n",
    "\n",
    "def preemphasis(x):\n",
    "    \n",
    "    '''\n",
    "        In high speed digital transmission, pre-emphasis is used to improve signal quality at the output of a \n",
    "        data transmission. \n",
    "        In transmitting signals at high data rates, the transmission medium may introduce distortions, \n",
    "        so pre-emphasis is used to distort the transmitted signal to correct for this distortion.\n",
    "    \n",
    "        ARGS: Time-Intensity Representation Of WaveForm\n",
    "    \n",
    "        RETURNS: Time-Intensity Representation Of Waveform With Improved Signal Quality With Reduced Noise\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return signal.lfilter([1, -preemphasis], [1], x)\n",
    "\n",
    "\n",
    "def inv_preemphasis(x):\n",
    "    \n",
    "    '''\n",
    "        DE-EMPHASIS\n",
    "    \n",
    "        ARGS : Time-Intensity Representation Of WaveForm\n",
    "        \n",
    "        RETURNS: Time-Intensity Representation Of WaveForm With Added Noise\n",
    "    '''\n",
    "    \n",
    "    return signal.lfilter([1], [1, -preemphasis], x)\n",
    "\n",
    "\n",
    "def spectrogram(y):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "        Converts a WaveForm To Spectogram using Short-Time-Fourier-Transform\n",
    "        And Then Converting Amplitude to Decibels For Proper Scaling\n",
    "        \n",
    "        ARGS: Time-Intensity Representation Of WaveForm\n",
    "        \n",
    "        RETURNS: SPECTOGRAM\n",
    "    '''\n",
    "    \n",
    "    D = _stft(preemphasis(y))  #Short-Time-Fourier-Transform\n",
    "    \n",
    "    S = _amp_to_db(np.abs(D)) - ref_db  #Converts Waveform To Spectogram\n",
    "    \n",
    "    return _normalize(S)\n",
    "\n",
    "def save_spec(spectrogram,path):\n",
    "    \n",
    "    '''\n",
    "        Converts The Spectogram To WaveForm And Then Save It To The Given Path\n",
    "\n",
    "        ARGS: Spectogram , Path\n",
    "        \n",
    "        RETURNS: Nothing , Saves Spectogram To Given Path\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    wav = inv_spectrogram(spectrogram)\n",
    "    save_wav(wav,path)\n",
    "\n",
    "def inv_spectrogram(spectrogram):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "        Converts Spectogram To Waveform\n",
    "        \n",
    "        ARGS: Spectogram\n",
    "        \n",
    "        RETURNS: Time-Intensity Representaion Of WaveForm\n",
    "     \n",
    "    '''\n",
    "    S = _db_to_amp(_denormalize(spectrogram) + ref_db)  # Convert back to linear\n",
    "    return inv_preemphasis(_griffin_lim(S ** power))          # Reconstruct phase\n",
    "\n",
    "def inv_spectrogram_tensorflow(spectrogram):\n",
    "    \n",
    "    '''Builds computational graph to convert spectrogram to waveform using TensorFlow.\n",
    "    Unlike inv_spectrogram, this does NOT invert the preemphasis. The caller should call\n",
    "    inv_preemphasis on the output after running the graph.\n",
    "    '''\n",
    "    S = _db_to_amp_tensorflow(_denormalize_tensorflow(spectrogram) + ref_db)\n",
    "    return _griffin_lim_tensorflow(tf.pow(S, power))\n",
    "\n",
    "def _griffin_lim_tensorflow(S):\n",
    "    \n",
    "    '''TensorFlow implementation of Griffin-Lim\n",
    "    Based on https://github.com/Kyubyong/tensorflow-exercises/blob/master/Audio_Processing.ipynb\n",
    "    '''\n",
    "    with tf.variable_scope('griffinlim'):\n",
    "        \n",
    "    # TensorFlow's stft and istft operate on a batch of spectrograms; create batch of size 1\n",
    "        S = tf.expand_dims(S, 0)\n",
    "        S_complex = tf.identity(tf.cast(S, dtype=tf.complex64))\n",
    "        y = _istft_tensorflow(S_complex)\n",
    "        for i in range(griffin_lim_iters):\n",
    "            est = _stft_tensorflow(y)\n",
    "            angles = est / tf.cast(tf.maximum(1e-8, tf.abs(est)), tf.complex64)\n",
    "            y = _istft_tensorflow(S_complex * angles)\n",
    "    return tf.squeeze(y, 0)\n",
    "\n",
    "def _denormalize_tensorflow(S):\n",
    "    \n",
    "    return (tf.clip_by_value(S, 0, 1) * -min_db) + min_db\n",
    "\n",
    "def _db_to_amp_tensorflow(x):\n",
    "    \n",
    "    return tf.pow(tf.ones(tf.shape(x)) * 10.0, x * 0.05)\n",
    "  \n",
    "def _griffin_lim(S):\n",
    "    \n",
    "    ''' To  retrieve  a time-domain signal from its amplitude spectrogram,\n",
    "        the corresponding phase is required. One of the popular phase reconstruction methods\n",
    "        is the Griffin–Lim algorithm (GLA), which is based on the re-dundancy of the \n",
    "        Short-Time Fourier transform\n",
    "\n",
    "        Based on https://github.com/librosa/librosa/issues/434\n",
    "\n",
    "        ARGS: Spectogram\n",
    "\n",
    "        RETURNS: Time-Intensity Representation of WaveForm With Reconstructed Phase\n",
    "    \n",
    "    '''\n",
    "    angles = np.exp(2j * np.pi * np.random.rand(*S.shape))\n",
    "    S_complex = np.abs(S).astype(np.complex)\n",
    "    y = _istft(S_complex * angles)\n",
    "    for i in range(griffin_lim_iters):\n",
    "        angles = np.exp(1j * np.angle(_stft(y)))\n",
    "        y = _istft(S_complex * angles)\n",
    "    return y\n",
    "\n",
    "\n",
    "def _stft(y):\n",
    "    \n",
    "    '''\n",
    "        Implementation Of Short-Time Fourier Transform Usiing Librosa\n",
    "\n",
    "        ARGS: Time-Intensity Representaion Of WaveForm\n",
    "        \n",
    "        RETURNS: Amplitude-Frequency Domain Representation Of A WaveForm With Specific Time Hops\n",
    "\n",
    "    '''\n",
    "    \n",
    "    n_fft, hop_length, win_length = _stft_parameters()\n",
    "    return librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "\n",
    "def _istft(y):\n",
    "    \n",
    "    '''\n",
    "        Inverse-Short-Time Fourier Transform - Converts a Complex Spectogram To A Time Domain Representaion\n",
    "        Of The Waveform\n",
    "    \n",
    "        ARGS: Spectogram\n",
    "        \n",
    "        RETURNS: Time-Intensity Representation Of WaveForm\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    _, hop_length, win_length = _stft_parameters()\n",
    "    return librosa.istft(y, hop_length=hop_length, win_length=win_length)\n",
    "\n",
    "def _istft_tensorflow(stfts):\n",
    "    \n",
    "    n_fft, hop_length, win_length = _stft_parameters()\n",
    "    return tf.contrib.signal.inverse_stft(stfts, win_length, hop_length, n_fft)\n",
    "\n",
    "def _stft_tensorflow(signals):\n",
    "    \n",
    "    n_fft, hop_length, win_length = _stft_parameters()\n",
    "    return tf.contrib.signal.stft(signals, win_length, hop_length, n_fft, pad_end=False)\n",
    "\n",
    "def _stft_parameters():\n",
    "    \n",
    "    \n",
    "    '''\n",
    "        Defining Necessary Parameters to perform Short-Time Fourier Transform\n",
    "\n",
    "        ARGS: None\n",
    "\n",
    "        OUTPUT: Necessary Parameters\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    n_fft = n_fft\n",
    "    hop_length = int(frame_shift * sr)\n",
    "    win_length = int(frame_length  * sr)\n",
    "    hop_length = hop_length\n",
    "    win_length = win_length\n",
    "    return n_fft, hop_length, win_length\n",
    "\n",
    "\n",
    "# Conversions:\n",
    "\n",
    "\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    \n",
    "    '''\n",
    "    Converts Amplitude To Decibel Values\n",
    "    \n",
    "    ARGS: Amplitude - Frequency Representation Of WaveForm\n",
    "    \n",
    "    RETURNS: Decible- Frequency Representaion Of WaveForm\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return 20 * np.log10(np.maximum(1e-5, x))\n",
    "\n",
    "def _db_to_amp(x):\n",
    "    \n",
    "    '''\n",
    "        Converts a Decibel-Frequency Representation To Amplitude-Frequency Representation Of A WaveForm\n",
    "\n",
    "    \n",
    "        ARGS: Decible - Frequency Representation Of WaveForm\n",
    "\n",
    "        RETURNS: Amplitude- Frequency Representaion Of WaveForm\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return np.power(10.0, x * 0.05)\n",
    "\n",
    "\n",
    "def _normalize(S):\n",
    "    \n",
    "    '''\n",
    "        Normalizes A Spectogram By Clipping Or Limiting Values In a Spectogram Between 0 and 1\n",
    "\n",
    "        ARGS: Spectogram\n",
    "\n",
    "        RETURNS: Normalized Spectogram\n",
    "\n",
    "    ''' \n",
    "    \n",
    "    return np.clip((S - min_db) / -min_db, 0, 1)\n",
    "\n",
    "def _denormalize(S):\n",
    "    \n",
    "    '''\n",
    "        De-Normalizes or Reverts The Normalized Spectogram Back To Original Representation\n",
    "        \n",
    "        ARGS: Normalized Sepctogram\n",
    "        \n",
    "        RETURNS : De-Normalized Spectogram\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return (np.clip(S, 0, 1) * -min_db) + min_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90SEvxjp1QSu"
   },
   "source": [
    "<h1>Modules</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5dSu_GHG1QSw"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "def embedding(inputs, \n",
    "              vocab_size, \n",
    "              num_units, \n",
    "              zero_pad=False, \n",
    "              scale=True,\n",
    "              scope=\"embedding\", \n",
    "              reuse=None):\n",
    "    \n",
    "    '''Embeds a given tensor.\n",
    "    Args:\n",
    "      inputs: A `Tensor` with type `int32` or `int64` containing the ids\n",
    "         to be looked up in `lookup table`.\n",
    "      vocab_size: An int. Vocabulary size.\n",
    "      num_units: An int. Number of embedding hidden units.\n",
    "      zero_pad: A boolean. If True, all the values of the fist row (id 0)\n",
    "        should be constant zeros.\n",
    "      scale: A boolean. If True. the outputs is multiplied by sqrt num_units.\n",
    "      scope: Optional scope for `variable_scope`.\n",
    "      reuse: Boolean, whether to reuse the weights of a previous layer\n",
    "        by the same name.\n",
    "    Returns:\n",
    "      A `Tensor` with one more rank than inputs's. The last dimensionality\n",
    "        should be `num_units`.\n",
    "\n",
    "    For example,\n",
    "\n",
    "    ```\n",
    "    import tensorflow as tf\n",
    "\n",
    "    inputs = tf.to_int32(tf.reshape(tf.range(2*3), (2, 3)))\n",
    "    outputs = embedding(inputs, 6, 2, zero_pad=True)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print sess.run(outputs)\n",
    "    >>\n",
    "    [[[ 0.\t\t\t0.\t\t  ]\n",
    "      [ 0.09754146\t0.67385566]\n",
    "      [ 0.37864095 -0.35689294]]\n",
    "     [[-1.01329422 -1.09939694]\n",
    "      [ 0.7521342\t0.38203377]\n",
    "      [-0.04973143 -0.06210355]]]\n",
    "    ```\n",
    "\n",
    "    ```\n",
    "    import tensorflow as tf\n",
    "\n",
    "    inputs = tf.to_int32(tf.reshape(tf.range(2*3), (2, 3)))\n",
    "    outputs = embedding(inputs, 6, 2, zero_pad=False)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print sess.run(outputs)\n",
    "    >>\n",
    "    [[[-0.19172323 -0.39159766]\n",
    "      [-0.43212751 -0.66207761]\n",
    "      [ 1.03452027 -0.26704335]]\n",
    "     [[-0.11634696 -0.35983452]\n",
    "      [ 0.50208133\t0.53509563]\n",
    "      [ 1.22204471 -0.96587461]]]\t \n",
    "    ```\t   \n",
    "    '''\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        lookup_table = tf.get_variable('lookup_table',\n",
    "                                       dtype=tf.float32,\n",
    "                                       shape=[vocab_size, num_units],\n",
    "                                       initializer=tf.contrib.layers.xavier_initializer())\n",
    "        if zero_pad:\n",
    "            lookup_table = tf.concat((tf.zeros(shape=[1, num_units]),\n",
    "                                      lookup_table[1:, :]), 0)\n",
    "        outputs = tf.nn.embedding_lookup(lookup_table, inputs)\n",
    "\n",
    "        if scale:\n",
    "            outputs = outputs * (num_units ** 0.5) \n",
    "\n",
    "    return outputs\n",
    "\n",
    "def conv1d(inputs, \n",
    "           filters, \n",
    "           size=1, \n",
    "           rate=1, \n",
    "           padding=\"SAME\", \n",
    "           causal=False,\n",
    "           use_bias=False,\n",
    "           scope=\"conv1d\"):\n",
    "    '''\n",
    "    Args:\n",
    "      inputs: A 3-D tensor of [batch, time, depth].\n",
    "      filters: An int. Number of outputs (=activation maps)\n",
    "      size: An int. Filter size.\n",
    "      rate: An int. Dilation rate.\n",
    "      padding: Either `SAME` or `VALID`.\n",
    "      causal: A boolean. If True, zeros of (kernel size - 1) * rate are padded on the left\n",
    "        for causality.\n",
    "      use_bias: A boolean.\n",
    "    \n",
    "    Returns:\n",
    "      A masked tensor of the sampe shape as `tensor`.\n",
    "    '''\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        if causal:\n",
    "            # pre-padding for causality\n",
    "            pad_len = (size - 1) * rate  # padding size\n",
    "            inputs = tf.pad(inputs, [[0, 0], [pad_len, 0], [0, 0]])\n",
    "            padding = \"VALID\"\n",
    "            \n",
    "        params = {\"inputs\":inputs, \"filters\":filters, \"kernel_size\":size,\n",
    "                \"dilation_rate\":rate, \"padding\":padding, \"activation\":None, \n",
    "                \"use_bias\":use_bias}\n",
    "        \n",
    "        out = tf.layers.conv1d(**params)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def conv1d_transpose(x,filters,kernel_size,strides):\n",
    "    \n",
    "    x = tf.expand_dims(x,1)\n",
    "    outputs=tf.layers.conv2d_transpose(x,filters,kernel_size,strides=(1,strides),padding='same')\n",
    "    outputs = tf.squeeze(outputs,1)\n",
    "    return outputs\n",
    "\n",
    "def Deconv1D(inputs, channels, kernel_size,dilation,scope=\"deconv1d\"):\n",
    "    \n",
    "    with tf.variable_scope(scope, reuse=False):\n",
    "        outputs = conv1d_transpose(inputs,channels,kernel_size,2)\n",
    "        return outputs\n",
    "\n",
    "def Conv1D(inputs, channels, kernel_size, dilation,causal=True,is_training=True,dropout=0.1, activation=None, scope = \"Conv1D\", reuse=None):\n",
    "    \n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        outputs = conv1d(inputs, channels, size=kernel_size, scope=scope, rate=dilation, causal=causal,)\n",
    "        if activation is not None:\n",
    "            outputs=activation(outputs)\n",
    "        return tf.layers.dropout(outputs, rate=dropout,training=is_training)\n",
    "\n",
    "def HConv1D(inputs, channels, kernel_size, dilation, causal=True,is_training=True, activation=None, scope = \"HConv1D\", reuse=None):\n",
    "    \n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        H = Conv1D(inputs, 2*channels, kernel_size, dilation=dilation, causal=causal,is_training=is_training,activation=activation,scope='c1d-H')\n",
    "        H1,H2 = tf.split(H,num_or_size_splits=2,axis=2)\n",
    "        H1 = tf.nn.sigmoid(H1)\n",
    "        return H1 * H2 + inputs * (1.0 - H1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYhoGMQX1QS4"
   },
   "source": [
    "<h1>TEXT2MEL MODEL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "fTngM1sV1QS6",
    "outputId": "330eb69f-deea-4f67-942b-b8784419cd87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0124 09:40:35.740669 15144 deprecation.py:323] From <ipython-input-6-e50906e3bedf>:45: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0124 09:40:35.777370 15144 deprecation.py:323] From <ipython-input-6-e50906e3bedf>:50: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "W0124 09:40:44.297040 15144 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0124 09:40:44.376401 15144 deprecation.py:323] From <ipython-input-4-b8be60587146>:113: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "W0124 09:40:44.378386 15144 deprecation.py:506] From C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0124 09:40:44.517476 15144 deprecation.py:323] From <ipython-input-4-b8be60587146>:136: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0124 09:40:45.536750 15144 deprecation.py:323] From <ipython-input-6-e50906e3bedf>:147: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0124 09:40:45.541202 15144 deprecation.py:506] From <ipython-input-6-e50906e3bedf>:148: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "W0124 09:40:45.861039 15144 deprecation.py:323] From C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Graph loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0124 09:40:48.199731 15144 deprecation.py:323] From <ipython-input-6-e50906e3bedf>:245: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "W0124 09:40:48.841713 15144 deprecation.py:323] From C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0124 09:40:49.550397 15144 deprecation.py:323] From C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "W0124 09:40:59.343255 11136 meta_graph.py:449] Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Tensor' object has no attribute 'to_proto'\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: LJSpeech-1.0/metadata.csv : The system cannot find the path specified.\r\n; No such process\n\t [[node IteratorGetNext (defined at <ipython-input-6-e50906e3bedf>:51) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IteratorGetNext:\n OneShotIterator (defined at <ipython-input-6-e50906e3bedf>:50)\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-e50906e3bedf>\", line 243, in <module>\n    g = Graph_Text2Mel(); print(\"Training Graph loaded\")\n  File \"<ipython-input-6-e50906e3bedf>\", line 92, in __init__\n    self.text, self.mel = get_data() # (N, T), (N,Tyr,nmels)\n  File \"<ipython-input-6-e50906e3bedf>\", line 51, in get_data\n    next_element = iterator.get_next()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1973, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: LJSpeech-1.0/metadata.csv : The system cannot find the path specified.\r\n; No such process\n\t [[{{node IteratorGetNext}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\u001b[0m in \u001b[0;36mmanaged_session\u001b[1;34m(self, master, config, start_standard_services, close_summary_writer)\u001b[0m\n\u001b[0;32m   1003\u001b[0m           start_standard_services=start_standard_services)\n\u001b[1;32m-> 1004\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e50906e3bedf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    249\u001b[0m             gs,l_m,l_m_l1,l_m_b,l_A,ops = sess.run([g.global_step,\n\u001b[1;32m--> 250\u001b[1;33m                 g.loss_mels,g.mel_l1_loss,g.mel_bin_div,g.A_loss,g.train_mel])\n\u001b[0m\u001b[0;32m    251\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Step %-7d : loss=%.05f,l1=%.05f,bin=%.05f,A_loss=%.05f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_m_l1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_m_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: LJSpeech-1.0/metadata.csv : The system cannot find the path specified.\r\n; No such process\n\t [[node IteratorGetNext (defined at <ipython-input-6-e50906e3bedf>:51) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IteratorGetNext:\n OneShotIterator (defined at <ipython-input-6-e50906e3bedf>:50)\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-e50906e3bedf>\", line 243, in <module>\n    g = Graph_Text2Mel(); print(\"Training Graph loaded\")\n  File \"<ipython-input-6-e50906e3bedf>\", line 92, in __init__\n    self.text, self.mel = get_data() # (N, T), (N,Tyr,nmels)\n  File \"<ipython-input-6-e50906e3bedf>\", line 51, in get_data\n    next_element = iterator.get_next()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1973, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e50906e3bedf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"mel1.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[0mshowmels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"a0.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m                 \u001b[0mshowmels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"a1.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\u001b[0m in \u001b[0;36mmanaged_session\u001b[1;34m(self, master, config, start_standard_services, close_summary_writer)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[1;31m# threads which are not checking for `should_stop()`.  They\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;31m# will be stopped when we close the session further down.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclose_summary_writer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose_summary_writer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m         \u001b[1;31m# Close the session to finish up all pending calls.  We do not care\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\u001b[0m in \u001b[0;36mstop\u001b[1;34m(self, threads, close_summary_writer, ignore_live_threads)\u001b[0m\n\u001b[0;32m    837\u001b[0m           \u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m           \u001b[0mstop_grace_period_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop_grace_secs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m           ignore_live_threads=ignore_live_threads)\n\u001b[0m\u001b[0;32m    840\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m       \u001b[1;31m# Close the writer last, in case one of the running threads was using it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[0;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mstop_on_exception\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=bare-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_timer_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m           \u001b[0mnext_timer_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer_interval_secs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\u001b[0m in \u001b[0;36mrun_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m       summary_strs, global_step = self._sess.run(\n\u001b[1;32m-> 1045\u001b[1;33m           [self._sv.summary_op, self._sv.global_step])\n\u001b[0m\u001b[0;32m   1046\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m       \u001b[0msummary_strs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: LJSpeech-1.0/metadata.csv : The system cannot find the path specified.\r\n; No such process\n\t [[node IteratorGetNext (defined at <ipython-input-6-e50906e3bedf>:51) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IteratorGetNext:\n OneShotIterator (defined at <ipython-input-6-e50906e3bedf>:50)\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-e50906e3bedf>\", line 243, in <module>\n    g = Graph_Text2Mel(); print(\"Training Graph loaded\")\n  File \"<ipython-input-6-e50906e3bedf>\", line 92, in __init__\n    self.text, self.mel = get_data() # (N, T), (N,Tyr,nmels)\n  File \"<ipython-input-6-e50906e3bedf>\", line 51, in get_data\n    next_element = iterator.get_next()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1973, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "#import audio\n",
    "\n",
    "def load_vocab():\n",
    "\n",
    "    # characters = \"PEاإأآبتثجحخدذرزسشصضطظعغفقكلمنهويىؤءةئ ًٌٍَُِّْ،.\" # Arabic character set\n",
    "    characters = \"PE abcdefghijklmnopqrstuvwxyz'.,?\"  # P: Padding E: End of Sentence\n",
    "\n",
    "    char2idx = {char: idx for idx, char in enumerate(characters)}\n",
    "    idx2char = {idx: char for idx, char in enumerate(characters)}\n",
    "    return char2idx, idx2char\n",
    "\n",
    "def clean(text):\n",
    "    text=text.lower()\n",
    "    re_list = r\"[^ abcdefghijklmnopqrstuvwxyz'.,?]\" # E: Empty. ignore G\n",
    "    #re_list = r\"[^اإأآبتثجحخدذرزسشصضطظعغفقكلمنهويىؤءةئ ًٌٍَُِّْ،.]\" # Arabic character set\n",
    "    _text = re.sub(re_list, \"\", text)\n",
    "    return(_text)\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    def mypyfunc(text):\n",
    "        text = text.decode(\"utf-8\")\n",
    "        items = text.split(\"|\")\n",
    "        char2idx,_=load_vocab()\n",
    "        text = items[1]\n",
    "        text = clean(text)\n",
    "        source = [char2idx[c] for c in text+'E']\n",
    "        dest = items[0]\n",
    "        mels = np.load(os.path.join(data_dir, \"mels\", dest + \".npy\"))\n",
    "        mels = mels[::4,:]\n",
    "        return np.array(source, dtype=np.int32),mels\n",
    "    def _pad(text,mel):\n",
    "        text = tf.pad(text, ((0, maxlen),))[:maxlen] # (Tx,)\n",
    "        mel = tf.pad(mel, ((0, Tyr), (0, 0)))[:Tyr] # (Tyr, n_mels)\n",
    "        return text,mel\n",
    "    dataset = tf.data.TextLineDataset(tf.convert_to_tensor(metafile))\n",
    "    dataset = dataset.map(lambda text: tuple(tf.py_func(mypyfunc, [text], [tf.int32, tf.float32])))\n",
    "    dataset = dataset.map(_pad)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(buffer_size=400)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    return(next_element)\n",
    "\n",
    "\n",
    "\n",
    "def w_fun(n, t):\n",
    "    return 1 - np.exp(-((n/(maxlen-1) - t/(Tyr-1))**2) / (2 * g**2))\n",
    "\n",
    "def guide_fn(x):\n",
    "    prva=-1\n",
    "    #return(x)\n",
    "    f=40\n",
    "    if x.shape[1]<=f:\n",
    "        return(x)\n",
    "    prva = np.argmax(x[:,f])-1\n",
    "    for i in range(f,x.shape[1]):\n",
    "\n",
    "        pos = np.argmax(x[:,i])\n",
    "        val = x[pos,i]\n",
    "        if (pos<prva) or (pos>prva+1):\n",
    "            x[:,i]=np.zeros(x.shape[0],dtype='f')\n",
    "            pp = min(x.shape[0]-1,prva+1)\n",
    "            x[pp,i]=1\n",
    "            #print(\"%d-Corrected from %d to %d - prva %d\"%(i,pos,pp,prva))\n",
    "        else:\n",
    "            x[:,i]=np.zeros(x.shape[0],dtype='f')\n",
    "            x[pos,i]=1\n",
    "            pass\n",
    "            #print(\"%d-Was ok %d - prva %d\"%(i,pos,prva))\n",
    "        prva=np.argmax(x[:,i])\n",
    "    return x\n",
    "\n",
    "\n",
    "def guide_atten(inputs): # 180,XX\n",
    "    return tf.py_func(guide_fn,[inputs],tf.float32)\n",
    "\n",
    "class Graph_Text2Mel():\n",
    "    def __init__(self, is_training=True):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            if is_training:\n",
    "                self.text, self.mel = get_data() # (N, T), (N,Tyr,nmels)\n",
    "                self.mel = tf.reshape(self.mel,shape=[-1,Tyr,n_mels])\n",
    "                w = np.fromfunction(w_fun, (maxlen, Tyr), dtype='f')\n",
    "                w = np.expand_dims(w,0)\n",
    "                w = np.repeat(w,batch_size,0)\n",
    "                self.A_guide = tf.convert_to_tensor(w) # B,180,870\n",
    "            else: # inference\n",
    "                self.text = tf.placeholder(tf.int32, shape=(None, maxlen))\n",
    "                self.mel = tf.placeholder(tf.float32, shape=(None,None,n_mels))\n",
    "\n",
    "            # define decoder inputs\n",
    "            if is_training:\n",
    "                self.decoder_inputs = tf.concat((tf.zeros_like(self.mel[:, :1,:]), self.mel[:, :-1,:]), 1) # shift mels to right\n",
    "            else:\n",
    "                self.decoder_inputs=self.mel\n",
    "            char2idx, idx2char = load_vocab()\n",
    "            with tf.variable_scope(\"Text2Mel\"):\n",
    "                with tf.variable_scope(\"TextEnc\"):\n",
    "                    self.emb=embedding(self.text,\n",
    "                                        vocab_size=len(char2idx), \n",
    "                                        num_units=e,\n",
    "                                        scale = False,\n",
    "                                        scope=\"embedding\") #in (N,T) out (N,T,e) (32,180,128)\n",
    "                    self.textenc=Conv1D(self.emb,d*2,1,1,causal=False,is_training=is_training,activation=tf.nn.relu,scope='c1d-1')\n",
    "                    self.textenc=Conv1D(self.textenc,d*2,1,1,causal=False,is_training=is_training,scope='c1d-2')\n",
    "                    for i in range(2):\n",
    "                        self.textenc=HConv1D(self.textenc,d*2,3,1,causal=False,is_training=is_training,scope='hc1d-1-%d'%i)\n",
    "                        self.textenc=HConv1D(self.textenc,d*2,3,3,causal=False,is_training=is_training,scope='hc1d-2-%d'%i)\n",
    "                        self.textenc=HConv1D(self.textenc,d*2,3,9,causal=False,is_training=is_training,scope='hc1d-3-%d'%i)\n",
    "                        self.textenc=HConv1D(self.textenc,d*2,3,27,causal=False,is_training=is_training,scope='hc1d-4-%d'%i)\n",
    "                    for i in range(2):\n",
    "                        self.textenc=HConv1D(self.textenc,d*2,3,1,causal=False,is_training=is_training,scope='hc1d-11-%d'%i)\n",
    "                    for i in range(2):\n",
    "                        self.textenc=HConv1D(self.textenc,d*2,1,1,causal=False,is_training=is_training,scope='hc1d-12-%d'%i) #(N,T,2*d) (32,180,512)\n",
    "\n",
    "\n",
    "                    self.K,self.V = tf.split(self.textenc,num_or_size_splits=2,axis=2)  #k=(B,N,d) v=(B,N,d)\n",
    "                with tf.variable_scope(\"AudioEnc\"):\n",
    "                    self.audioenc = Conv1D(self.decoder_inputs,d,1,1,is_training=is_training,activation=tf.nn.relu,scope='c1d-1') # from (B,Ty,80) -> (B,Ty,d)\n",
    "                    self.audioenc = Conv1D(self.audioenc,d,1,1,is_training=is_training,activation=tf.nn.relu,scope='c1d-2')\n",
    "                    self.audioenc = Conv1D(self.audioenc,d,1,1,is_training=is_training,scope='c1d-3')\n",
    "                    for i in range(2):\n",
    "                        self.audioenc=HConv1D(self.audioenc,d,3,1,is_training=is_training,scope='hc1d-1-%d'%i)\n",
    "                        self.audioenc=HConv1D(self.audioenc,d,3,3,is_training=is_training,scope='hc1d-2-%d'%i)\n",
    "                        self.audioenc=HConv1D(self.audioenc,d,3,9,is_training=is_training,scope='hc1d-3-%d'%i)\n",
    "                        self.audioenc=HConv1D(self.audioenc,d,3,27,is_training=is_training,scope='hc1d-4-%d'%i)\n",
    "                    for i in range(2):\n",
    "                        self.audioenc=HConv1D(self.audioenc,d,3,3,is_training=is_training,scope='hc1d-11-%d'%i)\n",
    "                    self.Q = self.audioenc                    # (B,Ty,d)\n",
    "\n",
    "                self.KT = tf.transpose(self.K,perm=[0,2,1]) # B,d,180\n",
    "                self.VT = tf.transpose(self.V,perm=[0,2,1]) # B,d,180\n",
    "                self.QT = tf.transpose(self.Q,perm=[0,2,1]) # B,d,870\n",
    "\n",
    "                self.A = tf.matmul(self.K,self.QT)    # (B,180,d) * (B,d,870) = (B,180,870)\n",
    "                self.A *= tf.sqrt(1/tf.to_float(d))\n",
    "                self.A = tf.nn.softmax(self.A,dim=1) #B,180,870\n",
    "                if not is_training:\n",
    "                    self.A = tf.map_fn(guide_atten,self.A,parallel_iterations=1)\n",
    "                    \n",
    "                self.R = tf.matmul(self.VT,self.A)      # B,d,180 * B,180,870 -> B,d,870\n",
    "                self.RT = tf.transpose(self.R,perm=[0,2,1]) # B,870,d\n",
    "                self.Rhat = tf.concat((self.RT,self.Q),2)   # (B,Ty,d),(B,Ty,d) --> (B,Ty,2d)\n",
    "                with tf.variable_scope(\"AudioDec\"):\n",
    "                    self.audiodec = Conv1D(self.Rhat,d,1,1,is_training=is_training,scope='c1d-1')\n",
    "                    self.audiodec=HConv1D(self.audiodec,d,3,1,is_training=is_training,scope='hc1d-1')\n",
    "                    self.audiodec=HConv1D(self.audiodec,d,3,3,is_training=is_training,scope='hc1d-2')\n",
    "                    self.audiodec=HConv1D(self.audiodec,d,3,9,is_training=is_training,scope='hc1d-3')\n",
    "                    self.audiodec=HConv1D(self.audiodec,d,3,27,is_training=is_training,scope='hc1d-4')\n",
    "                    for i in range(2):\n",
    "                        self.audiodec=HConv1D(self.audiodec,d,3,1,is_training=is_training,scope='hc1d-5-%d'%i)\n",
    "                    for i in range(3):\n",
    "                        self.audiodec=Conv1D(self.audiodec,d,1,1,dropout=0,is_training=is_training,scope='c1d-2-%d'%i,activation=tf.nn.relu)\n",
    "                    self.mel_logits = Conv1D(self.audiodec,n_mels,1,1,dropout=0,is_training=is_training,scope='c1d-3') # (B,Tyr,nmels)\n",
    "                    self.mel_output = tf.nn.sigmoid(self.mel_logits)                            #(B,Tyr,nmels)\n",
    "\n",
    "            if is_training:  \n",
    "                # Loss\n",
    "                self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "                #self.learning_rate = _learning_rate_decay(self.global_step)\n",
    "\n",
    "                #self.learning_rate = tf.train.exponential_decay(lr,self.global_step,1500,0.9)\n",
    "                self.learning_rate = lr//4\n",
    "                if masking:\n",
    "                    self.is_target = tf.to_float(tf.not_equal(self.mel,0))\n",
    "                    #self.mel_l1_loss = tf.reduce_mean(tf.abs(self.mel-self.mel_output))\n",
    "                    self.mel_l1_loss = tf.reduce_sum(tf.abs(self.mel-self.mel_output)*self.is_target)/tf.reduce_sum(self.is_target)\n",
    "\n",
    "                    #self.mel_bin_div = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.mel_logits,labels=self.mel))\n",
    "                    self.mel_bin_div = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.mel_logits,labels=self.mel)\n",
    "                    self.mel_bin_div = tf.reduce_sum(self.mel_bin_div*self.is_target)/tf.reduce_sum(self.is_target)\n",
    "                else:\n",
    "                    self.mel_l1_loss = tf.reduce_mean(tf.abs(self.mel-self.mel_output))\n",
    "                    self.mel_bin_div = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.mel_logits,labels=self.mel))\n",
    "\n",
    "                self.A_loss = tf.reduce_mean(self.A_guide*self.A)\n",
    "\n",
    "\n",
    "                self.loss_mels = self.mel_l1_loss + self.mel_bin_div + 10*self.A_loss\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=b1, beta2=b2, epsilon=eps)\n",
    "                #self.gvs = self.optimizer.compute_gradients(self.loss_mels) \n",
    "                #self.clipped = []\n",
    "                #for grad, var in self.gvs:\n",
    "                    #if grad is not None:\n",
    "                        #grad = tf.clip_by_norm(grad, max_grad_norm)\n",
    "    \n",
    "                    #self.clipped.append((grad, var))\n",
    "                self.train_mel = self.optimizer.minimize(self.loss_mels,global_step=self.global_step)\n",
    "                tf.summary.scalar('loss_mels', self.loss_mels)\n",
    "                tf.summary.scalar('loss_mel_l1', self.mel_l1_loss)\n",
    "                tf.summary.scalar('loss_mel_binary', self.mel_bin_div)\n",
    "                tf.summary.scalar('loss_Attention', self.A_loss)\n",
    "                tf.summary.scalar('learning_rate', self.learning_rate)\n",
    "            self.merged = tf.summary.merge_all()\n",
    "\n",
    "def show(mel1,mel2,name):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(np.transpose(mel1),interpolation='nearest',  cmap=plt.cm.afmhot, origin='lower')\n",
    "    plt.title(\"Generated\")\n",
    "    plt.colorbar()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(np.transpose(mel2),interpolation='nearest',  cmap=plt.cm.afmhot, origin='lower')\n",
    "    plt.title(\"Original\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig(name)\n",
    "    plt.cla()\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "def showmels(mel,msg,file):\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(8,4))\n",
    "    cax = ax.matshow(mel, interpolation='nearest',  cmap=plt.cm.afmhot, origin='lower')\n",
    "    fig.colorbar(cax)\n",
    "    plt.title(msg+str(len(msg)))\n",
    "    plt.savefig(file,format='png')\n",
    "    plt.cla()\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "def _learning_rate_decay(global_step):\n",
    "    # Noam scheme from tensor2tensor:\n",
    "    step = tf.cast(global_step + 1, dtype=tf.float32)\n",
    "    return init_lr * warmup_steps**0.5 * tf.minimum(step * warmup_steps**-1.5, step**-0.5)\n",
    "\n",
    "def tdecode(text):\n",
    "    char2idx,idx2char=load_vocab()\n",
    "    return(\"\".join(idx2char[i] for i in text).split('P')[0])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "    g = Graph_Text2Mel(); print(\"Training Graph loaded\")\n",
    "    sv = tf.train.Supervisor(graph=g.graph, \n",
    "                             logdir=logdirmel,)\n",
    "                             #save_model_secs=0)\n",
    "    with sv.managed_session() as sess:\n",
    "        while not sv.should_stop():\n",
    "            gs,l_m,l_m_l1,l_m_b,l_A,ops = sess.run([g.global_step,\n",
    "                g.loss_mels,g.mel_l1_loss,g.mel_bin_div,g.A_loss,g.train_mel])\n",
    "            message = \"Step %-7d : loss=%.05f,l1=%.05f,bin=%.05f,A_loss=%.05f\" % (gs,l_m,l_m_l1,l_m_b,l_A)\n",
    "            sys.stdout.write('\\r'+message)\n",
    "            sys.stdout.flush()\n",
    "            if (gs+1) % logevery == 0:\n",
    "                gs,l_m,l_m_l1,l_m_b,l_A,t_i,m_i,a,m_o,ops = sess.run([g.global_step,\n",
    "                    g.loss_mels,g.mel_l1_loss,g.mel_bin_div,g.A_loss,g.text,g.mel,g.A,g.mel_output,g.train_mel])\n",
    "                message = \"Step %-7d : loss=%.05f,l1=%.05f,bin=%.05f,A_loss=%.05f\" % (gs,l_m,l_m_l1,l_m_b,l_A)\n",
    "                sys.stdout.write('\\r'+message)\n",
    "                sys.stdout.flush()\n",
    "                show(m_o[0],m_i[0],\"mel0.png\")\n",
    "                show(m_o[1],m_i[1],\"mel1.png\")\n",
    "                showmels(a[0],tdecode(t_i[0]),\"a0.png\")\n",
    "                showmels(a[1],tdecode(t_i[1]),\"a1.png\")\n",
    "\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCQHYrRF1QS_"
   },
   "source": [
    "<h1>SPECTOGRAM SUPER RESOLUTION MODEL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "colab_type": "code",
    "id": "uAlvBoB11QTC",
    "outputId": "f01b2fe2-d00b-41f6-d1bf-90c9ef3701bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0124 09:41:22.496157 15144 deprecation.py:323] From <ipython-input-4-b8be60587146>:120: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Graph loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0124 09:41:31.111390 11160 meta_graph.py:449] Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Tensor' object has no attribute 'to_proto'\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: LJSpeech-1.0/metadata.csv : The system cannot find the path specified.\r\n; No such process\n\t [[node IteratorGetNext (defined at <ipython-input-7-30da31b5104a>:34) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IteratorGetNext:\n OneShotIterator (defined at <ipython-input-7-30da31b5104a>:33)\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-30da31b5104a>\", line 131, in <module>\n    g = Graph_SSR(); print(\"Training Graph loaded\")\n  File \"<ipython-input-7-30da31b5104a>\", line 43, in __init__\n    self.mel, self.mag=get_data() # (N,Tyr,nmels), (N,Ty,1+n_ffts//2)\n  File \"<ipython-input-7-30da31b5104a>\", line 34, in get_data\n    next_element = iterator.get_next()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1973, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: LJSpeech-1.0/metadata.csv : The system cannot find the path specified.\r\n; No such process\n\t [[{{node IteratorGetNext}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\u001b[0m in \u001b[0;36mmanaged_session\u001b[1;34m(self, master, config, start_standard_services, close_summary_writer)\u001b[0m\n\u001b[0;32m   1003\u001b[0m           start_standard_services=start_standard_services)\n\u001b[1;32m-> 1004\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-30da31b5104a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    137\u001b[0m             gs,l_M,l_M_l1,l_M_b,ops = sess.run([g.global_step,\n\u001b[1;32m--> 138\u001b[1;33m                 g.loss_mags,g.mag_l1_loss,g.mag_bin_div,g.train_mag])\n\u001b[0m\u001b[0;32m    139\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Step %d : l=%.05f (Ml1=%.05f,Mb=%.05f)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_M\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_M_l1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_M_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: LJSpeech-1.0/metadata.csv : The system cannot find the path specified.\r\n; No such process\n\t [[node IteratorGetNext (defined at <ipython-input-7-30da31b5104a>:34) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IteratorGetNext:\n OneShotIterator (defined at <ipython-input-7-30da31b5104a>:33)\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-30da31b5104a>\", line 131, in <module>\n    g = Graph_SSR(); print(\"Training Graph loaded\")\n  File \"<ipython-input-7-30da31b5104a>\", line 43, in __init__\n    self.mel, self.mag=get_data() # (N,Tyr,nmels), (N,Ty,1+n_ffts//2)\n  File \"<ipython-input-7-30da31b5104a>\", line 34, in get_data\n    next_element = iterator.get_next()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1973, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-30da31b5104a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[1;31m#audio.save_spec(M_o[1].T,\"out1.wav\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                 \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"mag0.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"mag1.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\u001b[0m in \u001b[0;36mmanaged_session\u001b[1;34m(self, master, config, start_standard_services, close_summary_writer)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[1;31m# threads which are not checking for `should_stop()`.  They\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;31m# will be stopped when we close the session further down.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclose_summary_writer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose_summary_writer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m         \u001b[1;31m# Close the session to finish up all pending calls.  We do not care\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\u001b[0m in \u001b[0;36mstop\u001b[1;34m(self, threads, close_summary_writer, ignore_live_threads)\u001b[0m\n\u001b[0;32m    837\u001b[0m           \u001b[0mthreads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m           \u001b[0mstop_grace_period_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop_grace_secs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m           ignore_live_threads=ignore_live_threads)\n\u001b[0m\u001b[0;32m    840\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m       \u001b[1;31m# Close the writer last, in case one of the running threads was using it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[0;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mstop_on_exception\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=bare-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_timer_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m           \u001b[0mnext_timer_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer_interval_secs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\u001b[0m in \u001b[0;36mrun_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m       summary_strs, global_step = self._sess.run(\n\u001b[1;32m-> 1045\u001b[1;33m           [self._sv.summary_op, self._sv.global_step])\n\u001b[0m\u001b[0;32m   1046\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m       \u001b[0msummary_strs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: LJSpeech-1.0/metadata.csv : The system cannot find the path specified.\r\n; No such process\n\t [[node IteratorGetNext (defined at <ipython-input-7-30da31b5104a>:34) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node IteratorGetNext:\n OneShotIterator (defined at <ipython-input-7-30da31b5104a>:33)\n\nOriginal stack trace for 'IteratorGetNext':\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-30da31b5104a>\", line 131, in <module>\n    g = Graph_SSR(); print(\"Training Graph loaded\")\n  File \"<ipython-input-7-30da31b5104a>\", line 43, in __init__\n    self.mel, self.mag=get_data() # (N,Tyr,nmels), (N,Ty,1+n_ffts//2)\n  File \"<ipython-input-7-30da31b5104a>\", line 34, in get_data\n    next_element = iterator.get_next()\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\n    output_shapes=self._structure._flat_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1973, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Aditya Pandya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "#import audio\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    def mypyfunc(text):\n",
    "        text = text.decode(\"utf-8\")\n",
    "        items = text.split(\"|\")\n",
    "        dest = items[0]\n",
    "        mels = np.load(os.path.join(data_dir, \"mels\", dest + \".npy\"))\n",
    "        mels = mels[::4,:]\n",
    "        mags = np.load(os.path.join(data_dir, \"mags\", dest + \".npy\"))\n",
    "        return mels,mags\n",
    "    def _pad(mel,mag):\n",
    "        mel = tf.pad(mel, ((0, Tyr), (0, 0)))[:Tyr] # (Tyr, n_mels)\n",
    "        mag = tf.pad(mag, ((0, Ty), (0, 0)))[:Ty] # (Ty, 1+n_fft/2)\n",
    "        return mel,mag\n",
    "    dataset = tf.data.TextLineDataset(tf.convert_to_tensor(metafile))\n",
    "    dataset = dataset.map(lambda text: tuple(tf.py_func(mypyfunc, [text], [tf.float32, tf.float32])))\n",
    "    dataset = dataset.map(_pad)\n",
    "    dataset = dataset.shuffle(buffer_size=400)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "    return(next_element)\n",
    "\n",
    "\n",
    "class Graph_SSR():\n",
    "    def __init__(self, is_training=True):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            if is_training:\n",
    "                self.mel, self.mag=get_data() # (N,Tyr,nmels), (N,Ty,1+n_ffts//2)\n",
    "                self.mel = tf.reshape(self.mel,shape=[-1,Tyr,n_mels])\n",
    "            else: # inference\n",
    "                self.mel = tf.placeholder(tf.float32, shape=(None,None,n_mels))\n",
    "            with tf.variable_scope(\"SSRN\"):\n",
    "                self.ssrn = Conv1D(self.mel,c,1,1,causal=False,is_training=is_training,scope='c1d-1')\n",
    "                self.ssrn = HConv1D(self.ssrn,c,3,1,causal=False,is_training=is_training,scope='hc1d-1')\n",
    "                self.ssrn = HConv1D(self.ssrn,c,3,3,causal=False,is_training=is_training,scope='hc1d-2')\n",
    "                for i in range(2):\n",
    "                    self.ssrn = Deconv1D(self.ssrn,c,2,1,scope='deconv-%d'%i)\n",
    "                    self.ssrn = HConv1D(self.ssrn,c,3,1,causal=False,is_training=is_training,scope='hc1d-31-%d'%i)\n",
    "                    self.ssrn = HConv1D(self.ssrn,c,3,3,causal=False,is_training=is_training,scope='hc1d-32-%d'%i)\n",
    "                self.ssrn = Conv1D(self.ssrn,c*2,1,1,causal=False,is_training=is_training,scope='c1d-2')\n",
    "                for i in range(2):\n",
    "                    self.ssrn=HConv1D(self.ssrn,c*2,3,1,causal=False,is_training=is_training,scope='hc1d-4-%d'%i)\n",
    "                self.ssrn = Conv1D(self.ssrn,fd,1,1,causal=False,is_training=is_training,scope='c1d-3')\n",
    "                for i in range(2):\n",
    "                    self.ssrn=Conv1D(self.ssrn,fd,1,1,causal=False,is_training=is_training,activation=tf.nn.relu,scope='c1d-4-%d'%i)\n",
    "                self.mag_logits = Conv1D(self.ssrn,fd,1,1,causal=False,is_training=is_training,scope='c1d-5')\n",
    "                self.mag_output = tf.nn.sigmoid(self.mag_logits)\n",
    "            if is_training:  \n",
    "                # Loss\n",
    "                self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "                #self.learning_rate = _learning_rate_decay(self.global_step)\n",
    "\n",
    "                #self.learning_rate = tf.train.exponential_decay(lr,self.global_step,3000,0.9)\n",
    "                self.learning_rate = lr\n",
    "\n",
    "                self.l1 = tf.abs(self.mag - self.mag_output)\n",
    "                self.n_priority = int(3000/(sr*0.5) * fd)\n",
    "                self.mag_l1_loss = 0.5*tf.reduce_mean(self.l1) + 0.5 * tf.reduce_mean(self.l1[:,:,0:self.n_priority]) \n",
    "                #self.mag_l1_loss = tf.reduce_mean(tf.abs(self.mag-self.mag_output))\n",
    "                #self.mag_l1_loss = tf.reduce_sum(tf.abs(self.mag-self.mag_output)*tf.to_float(tf.not_equal(self.mag,0)))/tf.reduce_sum(tf.to_float(tf.not_equal(self.mag,0)))\n",
    "                self.mag_bin_div = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.mag_logits,labels=self.mag))\n",
    "                #self.mag_bin_div = tf.nn.sigmoid_cross_entropy_with_logits(logits=self.mag_logits,labels=self.mag)\n",
    "                #self.mag_bin_div = tf.reduce_sum(self.mag_bin_div*tf.to_float(tf.not_equal(self.mag,0)))/tf.reduce_sum(tf.to_float(tf.not_equal(self.mag,0)))\n",
    "\n",
    "                self.loss_mags = self.mag_l1_loss + self.mag_bin_div\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=b1, beta2=b2, epsilon=eps)\n",
    "                #self.gvs = self.optimizer.compute_gradients(self.loss_mels) \n",
    "                #self.clipped = []\n",
    "                #for grad, var in self.gvs:\n",
    "                    #if grad is not None:\n",
    "                        #grad = tf.clip_by_norm(grad, max_grad_norm)\n",
    "                        \n",
    "                    #self.clipped.append((grad, var))\n",
    "                #self.train_op = self.optimizer.apply_gradients(self.clipped, global_step=self.global_step)\n",
    "                self.train_mag = self.optimizer.minimize(self.loss_mags,global_step=self.global_step)\n",
    "                tf.summary.scalar('loss_mags', self.loss_mags)\n",
    "                tf.summary.scalar('loss_mag_binary', self.mag_bin_div)\n",
    "                tf.summary.scalar('loss_mag_l1', self.mag_l1_loss)\n",
    "                tf.summary.scalar('learning_rate', self.learning_rate)\n",
    "            else:\n",
    "                self.wav_output = inv_spectrogram_tensorflow(self.mag_output)\n",
    "            self.merged = tf.summary.merge_all()\n",
    "\n",
    "def show(mel1,mel2,name):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(np.transpose(mel1),interpolation='nearest', aspect='auto', cmap=plt.cm.afmhot, origin='lower')\n",
    "    plt.title(\"Generated\")\n",
    "    plt.colorbar()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(np.transpose(mel2),interpolation='nearest', aspect='auto', cmap=plt.cm.afmhot, origin='lower')\n",
    "    plt.title(\"Original\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig(name)\n",
    "    plt.cla()\n",
    "    plt.close('all')\n",
    "\n",
    "      \n",
    "def showmels(mel,msg,file):\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(8,4))\n",
    "    cax = ax.matshow(mel, interpolation='nearest',  cmap=plt.cm.afmhot, origin='lower')\n",
    "    fig.colorbar(cax)\n",
    "    plt.title(msg+str(len(msg)))\n",
    "    plt.savefig(file,format='png')\n",
    "    plt.cla()\n",
    "    plt.close('all')\n",
    "\n",
    "def _learning_rate_decay(global_step):\n",
    "    # Noam scheme from tensor2tensor:\n",
    "    step = tf.cast(global_step + 1, dtype=tf.float32)\n",
    "    return init_lr * warmup_steps**0.5 * tf.minimum(step * warmup_steps**-1.5, step**-0.5)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    g = Graph_SSR(); print(\"Training Graph loaded\")\n",
    "    sv = tf.train.Supervisor(graph=g.graph, \n",
    "                             logdir=logdirmag,)\n",
    "                             #save_model_secs=0)\n",
    "    with sv.managed_session() as sess:\n",
    "        while not sv.should_stop():\n",
    "            gs,l_M,l_M_l1,l_M_b,ops = sess.run([g.global_step,\n",
    "                g.loss_mags,g.mag_l1_loss,g.mag_bin_div,g.train_mag])\n",
    "            message = \"Step %d : l=%.05f (Ml1=%.05f,Mb=%.05f)\" % (gs,l_M,l_M_l1,l_M_b)\n",
    "            sys.stdout.write('\\r'+message)\n",
    "            sys.stdout.flush()\n",
    "            #print(message)\n",
    "            if (gs+1) % logevery == 0:\n",
    "                gs,l_M,l_M_l1,l_M_b,M_o,M_i,ops = sess.run([g.global_step,\n",
    "                    g.loss_mags,g.mag_l1_loss,g.mag_bin_div,\n",
    "                    g.mag_output, g.mag,g.train_mag])\n",
    "                message = \"Step %d : l=%.05f (Ml1=%.05f,Mb=%.05f)\" % (gs,l_M,l_M_l1,l_M_b)\n",
    "                sys.stdout.write('\\r'+message)\n",
    "                sys.stdout.flush()\n",
    "                #audio.save_spec(M_o[0].T,\"out0.wav\")\n",
    "                #audio.save_spec(M_o[1].T,\"out1.wav\")\n",
    "                show(M_o[0],M_i[0],\"mag0.png\")\n",
    "                show(M_o[1],M_i[1],\"mag1.png\")\n",
    "            \n",
    "\n",
    "\n",
    "    print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfAP5bl71QTJ"
   },
   "source": [
    "<h1>Synthesization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "id": "dX7nWWfH1QTL",
    "outputId": "13c9fbc3-2029-46c7-cbea-fa50864d7606"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The channel dimension of the inputs should be defined. Found `None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d5eb99d11ce2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m   \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSynth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m   \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hello\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"test.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m   \u001b[1;31m# parser = argparse.ArgumentParser()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d5eb99d11ce2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSynth\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmelmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraph_Text2Mel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraph_SSR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Graphs Loaded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e50906e3bedf>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, is_training)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# (B,Ty,d),(B,Ty,d) --> (B,Ty,2d)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AudioDec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudiodec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRhat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c1d-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudiodec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudiodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hc1d-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudiodec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudiodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hc1d-2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-b8be60587146>\u001b[0m in \u001b[0;36mConv1D\u001b[1;34m(inputs, channels, kernel_size, dilation, causal, is_training, dropout, activation, scope, reuse)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcausal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcausal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-b8be60587146>\u001b[0m in \u001b[0;36mconv1d\u001b[1;34m(inputs, filters, size, rate, padding, causal, use_bias, scope)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \"use_bias\":use_bias}\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\u001b[0m in \u001b[0;36mconv1d\u001b[1;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    216\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m       _scope=name)\n\u001b[1;32m--> 218\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m     \"\"\"\n\u001b[1;32m-> 1479\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m           \u001b[1;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1879\u001b[0m       \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1880\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1881\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1882\u001b[0m     \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m     \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    151\u001b[0m       \u001b[0mchannel_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       raise ValueError('The channel dimension of the inputs '\n\u001b[0m\u001b[0;32m    154\u001b[0m                        'should be defined. Found `None`.')\n\u001b[0;32m    155\u001b[0m     \u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The channel dimension of the inputs should be defined. Found `None`."
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import io\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "class Synth:\n",
    "\tdef __init__(self):\n",
    "\t\tself.melmodel = Graph_Text2Mel(is_training=False)\n",
    "\t\tself.magmodel = Graph_SSR(is_training=False)\n",
    "\t\tprint(\"Graphs Loaded\")\n",
    "\t\tself.c2i,_ = load_vocab()\n",
    "\t\tself.melsession = tf.Session(graph=self.melmodel.graph)\t\t\n",
    "\t\tself.magsession = tf.Session(graph=self.magmodel.graph)\n",
    "\t\twith self.melsession.as_default():\n",
    "\t\t\twith self.melmodel.graph.as_default():\n",
    "\t\t\t\tsaver = tf.train.Saver()\n",
    "\t\t\t\tsaver.restore(self.melsession,tf.train.latest_checkpoint(logdirmel))\n",
    "\t\tprint(\"Restored Mels\")\n",
    "\t\twith self.magsession.as_default():\n",
    "\t\t\twith self.magmodel.graph.as_default():\n",
    "\t\t\t\tsaver = tf.train.Saver()\n",
    "\t\t\t\tsaver.restore(self.magsession,tf.train.latest_checkpoint(logdirmag))\n",
    "\t\tprint(\"Restored Mags\")\n",
    "\tdef synth(self,text,save=None):\n",
    "\t\tinp = clean(text)\n",
    "\t\tprint(inp)\n",
    "\t\tx = [self.c2i[c] for c in inp+'E']\n",
    "\t\tx += [0]*(maxlen-len(x))\t\n",
    "\t\tx = np.array(x)\n",
    "\t\tx = x.reshape(1,-1)\n",
    "\t\twith self.melsession.as_default():\n",
    "\t\t\tpreds = np.zeros((1, 1, n_mels), np.float32)\n",
    "\t\t\tcnt = Tyr\n",
    "\t\t\tfor j in range(Tyr):\n",
    "\t\t\t\tsys.stdout.write('\\rProcessing %d' % j)\n",
    "\t\t\t\tsys.stdout.flush()\n",
    "\t\t\t\t_preds,a = self.melsession.run([self.melmodel.mel_output, self.melmodel.A], {self.melmodel.text: x, self.melmodel.mel: preds})\n",
    "\t\t\t\tpreds = np.concatenate((np.zeros((1,1,n_mels)),_preds),axis=1)  \n",
    "\t\t\t\tcnt -=1\n",
    "\t\t\t\tif np.argmax(a[0,:,-1]) >= len(inp)-3:\n",
    "\t\t\t\t\tcnt = min(cnt,10)\n",
    "\t\t\t\tif cnt<=0:\n",
    "\t\t\t\t\tbreak\n",
    "\t\twith self.magsession.as_default():\n",
    "\t\t\twav = self.magsession.run(self.magmodel.wav_output,{self.magmodel.mel: preds})\n",
    "\t\t\twav = audio.inv_preemphasis(wav)\n",
    "\t\t\tif save is not None:\n",
    "\t\t\t\taudio.save_wav(wav[0],save)\n",
    "\t\t\telse:\n",
    "\t\t\t\tout = io.BytesIO()\n",
    "\t\t\t\taudio.save_wav(wav[0], out)\n",
    "\t\t\t\treturn out.getvalue()\n",
    "\t\t\t#audio.save_spec(mags[0].T,\"out.wav\")\t\t\t\t\n",
    "\t\t#showmels(preds[0].T,\"Mel Prediction\",\"prediction.png\")\n",
    "\t\t#showmels(a[0],\"Attention\",\"attfinal.png\")\n",
    "\n",
    "#s = Synth()\n",
    "#s.load()\n",
    "#s.synth(\"Hillary Clinton made a surprise appearance on Sunday night in a Grammy Awards comedy bit that took a jab at President Trump.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  s = Synth()\n",
    "  s.synth(\"Hello\",\"test.wav\")\n",
    "  # parser = argparse.ArgumentParser()\n",
    "  # parser.add_argument('--text',help='Text to Synthesize',default='The Big Brown Fox Jumped Over The Lazy Dog')\n",
    "  # parser.add_argument('--file',help='File to save to ',default='output.wav')\n",
    "  # args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolution Text to Speech (DC_TTS)\n",
    "This is an implementation of the paper \"Efficiently Trainable Text-to-Speech System Based on Deep Convolutional  Networks with Guided Attention\" https://arxiv.org/abs/1710.08969\n",
    "\n",
    "# Prerequisite Knowledge\n",
    "\n",
    "To understand this notebook properly, you must have some knowledge about how sounds are dealt with, in data science and the various operations that are performed to convert a Waveform to a representaion suitable for analysis.\n",
    "Some Basic Concepts Are Mentioned Below :-\n",
    "\n",
    "## Fourier Transform (FT)\n",
    "\n",
    "Before we start with what Fourier Trasnform is, let us first understand some terminologies that we will need to know about to understand it in a better way\n",
    "\n",
    "### 1. Time-Domain Representation or a WaveForm\n",
    "A WaveForm or an audio signal is the raw representation of a sound wave as a function of <b>Time</b> and it's <b>Intensities</b>.\n",
    "This representaion is also known as the <b>Time-Domain Representation</b> or the <b>Time-Amplitude Representation</b> \n",
    "\n",
    "<img src=\"fig/time-domain.png\">\n",
    "\n",
    "### 2. Frequency-Domain Representation\n",
    "A Frequency-Domain Representation refers to the analysis of mathematical functions or signals with respect to frequency, rather than time.\n",
    "This representaion is also known as the <b>Frequency-Amplitude Representation</b> or the <b>Amplitude-Frequency Representation</b>. \n",
    "\n",
    "<img src=\"fig/frequency-domain.png\">\n",
    "\n",
    "Put simply, a time-domain graph shows how a signal changes over time, whereas a frequency-domain graph shows how much of the signal lies within each given frequency band over a range of frequencies.\n",
    "\n",
    "<img src=\"fig/time-domain and frequency-domain.png\">\n",
    "\n",
    "#### Now how does this all relate to the Fourier Trasnform?\n",
    "\n",
    "<b>The Fourier transform</b> (FT) decomposes a function of time (a signal) into its constituent frequencies. This is similar to the way a musical chord can be expressed in terms of the volumes and frequencies of its constituent notes. The term Fourier transform refers to both the frequency domain representation and the mathematical operation that associates the frequency domain representation to a function of time. \n",
    "Essentially A Fourier Trasnform when applied on a Signal Represented in the Time-Domain gets converted to the Frequency-Domain.\n",
    "\n",
    "<img src=\"fig/Time-domain-vs-frequency-domain-measurements.png\">\n",
    "\n",
    "#### Now the question arieses, why do we need to convert the signal to a Frequency-Domain representation ?\n",
    "\n",
    "Time domain signals, just provide the information regarding the value of a function/signal at any given instance. They do not convey the information as to the rate at which the signal is varying. Thus the need arises to represent the signal in another domain, describing the rate at which they vary, or the frequency.\n",
    "\n",
    "But we need both the aspects of Time-Domain as well as the Frequency-Domain to understand better the properties the WaveForm that we have.\n",
    "The Time-Domain Representation gives us the times at which the signal was perceived while the Frequency-Domain Representation tells us about the Frequency distribution of the WaveForm.\n",
    "\n",
    "<img src=\"fig/WHY_STFT.png\">\n",
    "\n",
    "#### This Problems brings us to our next Method\n",
    "\n",
    "## Short-Time Fourier Transform (STFT)\n",
    "\n",
    "The short-time Fourier transform (STFT), is a Fourier-related transform used to determine the sinusoidal frequency and phase content of local sections of a signal as it changes over time. In practice, the procedure for computing STFTs is to divide a longer time signal into shorter segments of equal length and then compute the Fourier transform separately on each shorter segment. This reveals the Fourier spectrum on each shorter segment. One then usually plots the changing spectra as a function of time. \n",
    "\n",
    "<img src=\"fig/stft.png\">\n",
    "\n",
    "## Spectograms\n",
    "\n",
    "The STFT is one of the most frequently used tools in speech analysis and processing. It describes the evolution of frequency components over time. Like the spectrum itself, one of the benefits of STFTs is that its parameters have a physical and intuitive interpretation.\n",
    "\n",
    "A further parallel with a spectrum is that the output of the STFT is complex-valued, though where the spectrum is a vector, the STFT output is a matrix. As a consequence, we cannot directly visualize the complex-valued output. Instead, STFTs are usually visualized using their log-spectra,  $20log10(X(h,k))$. Such 2 dimensional log-spectra can then be visualized with a heat-map known as a spectrogram.\n",
    "\n",
    "\n",
    "#### 3D- Visualization Of A Spectogram\n",
    "\n",
    "<img src=\"fig/spectogram.jpeg\">\n",
    "\n",
    "#### 2D- Representation With Color-Coded Amplitude\n",
    "\n",
    "<img src=\"fig/spectogram and waveform.png\">\n",
    "\n",
    "\n",
    "\n",
    "## MEL SCALE\n",
    "\n",
    "Let’s forget for a moment about all these lovely visualization and talk math. The Mel Scale, mathematically speaking, is the result of some non-linear transformation of the frequency scale. This Mel Scale is constructed such that sounds of equal distance from each other on the Mel Scale, also “sound” to humans as they are equal in distance from one another.\n",
    "In contrast to Hz scale, where the difference between 500 and 1000 Hz is obvious, whereas the difference between 7500 and 8000 Hz is barely noticeable.\n",
    "\n",
    "## MEL Spectogram\n",
    "\n",
    "We know now what is a Spectrogram, and also what is the Mel Scale, so the Mel Spectrogram, is, rather surprisingly, a Spectrogram with the Mel Scale as its y axis.\n",
    "\n",
    "<img src=\"fig/mel_spectogram.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Download Links\n",
    "\n",
    "LJSpeech dataset : **[Here](https://keithito.com/LJ-Speech-Dataset/)**\n",
    "The dataset will be downloaded when you run the notebook\n",
    "\n",
    "Pre-Trained models : **[Here](https://drive.google.com/file/d/15hlUmrAbSIjHABMiizCwusvfMp13wtdp/view?usp=sharing)**\n",
    "\n",
    "\n",
    "\n",
    "# How Does It Work ?\n",
    "\n",
    "The DC-TTS Model consits of 2 main Model:\n",
    "\n",
    "## Text2Mel Model :\n",
    "\n",
    "We train this model to synthesize a coarse MEL Spectogram from a given Text.\n",
    "This model consists of $4$ sub-modules\n",
    "\n",
    "### Text Encoder\n",
    "\n",
    "Encodes the input sentence $L$ = [c<sub>1</sub>,c<sub>2</sub>,c<sub>3</sub>.....c<sub>n</sub>] where c<sub>1</sub> , c<sub>2</sub> , c<sub>3</sub> .... c<sub>n</sub> are characters, into two Key and Value Matrices <b>K</b> and <b>V</b>\n",
    "\n",
    "$(K,V) = TextEncoder(L)$\n",
    "\n",
    "### Audio Encoder\n",
    "\n",
    "Encodes the coarse MEL-Spectogram of previously spoken speech, whose length is $T$, into a matrix $Q$.\n",
    "Takes in as input, the target audio Spectogram and outputs a queries matrix $Q$ of size $dxT$ , where $T$ is length of the audio clip.\n",
    "\n",
    "$Q$ $=$ $AudioEncoder$$($S<sub>1:F,1:T</sub>$)$\n",
    "\n",
    "\n",
    "### Attention\n",
    "\n",
    "An Attention Matrix $A$ evaluates how strongly the n<sup>th</sup> character c<sub>n</sub> and t<sup>th</sup> frame $S$<sub>1:F,T</sub> are related\n",
    "\n",
    "$A = softmax($K<sup>T</sup>${Q/d^{1/2}})$\n",
    "\n",
    "A<sub>nt</sub> ~ 1 implies that the modules is looking at n<sup>th</sup> Character c<sub>n</sub> at time frame t and it will look at c<sub>n</sub> or c<sub>n+1</sub> characters around them, at the subsequent time frame t+1.\n",
    "\n",
    "$R = Attention(Q,K,V) = V.A $\n",
    "\n",
    "\n",
    "\n",
    "### Audio Decoder\n",
    "\n",
    "The resultant $R$ is contatenated with the encoded audio $Q$ as $R' = [R,Q]$.\n",
    "Then $R'$ is decoded by the Audio Decoder module to synthesize a coarse MEL-Spectogram.\n",
    "\n",
    "$Y$<sub>1:F,2:T+1</sub> $= AudioDecoder(R')$\n",
    "\n",
    "The result $Y$<sub>1:F,2:T+1</sub> is compared with the temporally-shifted truth $S$<sub>1:F,2:T+1</sub> by a loss function and error is back propogaed to the network parameters.\n",
    "\n",
    "\n",
    "## Spectogram Super-Resolution Model :\n",
    "\n",
    "Super resolution is the process of upscaling and or improving the details within an image. Often a low resolution image is taken as an input and the same image is upscaled to a higher resolution, which is the output. The details in the high resolution output are filled in where the details are essentially unknown.\n",
    "\n",
    "Super resolution is essentially what you see in films and series like CSI where someone zooms into an image and it improves in quality and the details just appear.\n",
    "\n",
    "Similarly our SSR model does the same but for audio signals or spectograms.\n",
    "This model converts the coarse MEL-Spectogram generated by the Text2Mel Model to A Super-Resolution Spectogram.\n",
    "\n",
    "<img src=\"fig/ssr.jpeg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Voice Synthesis Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
